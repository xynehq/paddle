services:
  paddlex-server:
    image: paddlex/app:latest
    build:
      context: .               # build from current dir (Dockerfile + server.sh here)
      dockerfile: Dockerfile   # optional, defaults to "Dockerfile"
    container_name: paddlex-server
    environment:
      - PADDLEX_HPS_DEVICE_TYPE=gpu
      - IMAGE_CAPTIONING_ENABLED=${IMAGE_CAPTIONING_ENABLED:-true}  # Default: true
    volumes:
      - .:/app                 # mount current dir to /app
      - ./config_gpu_paddlex.pbtxt:/app/server/model_repo/layout-parsing/config_gpu.pbtxt
      # - ./paddlex/official_models:/root/.paddlex/official_models
    ports:
      - "8000:8000"            # Triton HTTP endpoint
      - "8001:8001"           # Triton gRPC endpoint
      - "8002:8002"            # Triton metrics endpoint
      - "8081:8081"            # Instance status endpoint exposed by Python backend
    shm_size: 8g               # equivalent to --shm-size 8g
    init: true                 # equivalent to --init
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - xyne

  blip-server:
    image: paddlex/app:latest
    container_name: blip-server
    profiles:
      - image-captioning
    volumes:
      - .:/app
      - ./config_gpu_blip.pbtxt:/app/server/model_repo/blip-caption/config_gpu.pbtxt
    working_dir: /app/server
    command: |
      bash -lc '
      cp model_repo/blip-caption/config_gpu.pbtxt model_repo/blip-caption/config.pbtxt && 
      tritonserver --model-repository=model_repo --model-control-mode=explicit --load-model=blip-caption --grpc-port=8004 --http-port=8003 --metrics-port=8005 --log-info=1 --log-warning=1 --log-error=1
      '
    ports:
      - "8003:8003"  # BLIP HTTP
      - "8004:8004"  # BLIP gRPC
      - "8005:8005"  # BLIP metrics endpoint
    shm_size: 1g
    init: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - xyne

networks:
  xyne:
    external: true
