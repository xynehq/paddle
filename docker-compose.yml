services:
  paddlex-server:
    build:
      context: .               # build from current dir (Dockerfile + server.sh here)
      dockerfile: Dockerfile   # optional, defaults to "Dockerfile"
    container_name: paddlex-server
    environment:
      - PADDLEX_HPS_DEVICE_TYPE=gpu
    volumes:
     - .:/app                 # mount current dir to /app
      - ./config_gpu.pbtxt:/app/server/model_repo/layout-parsing/config_gpu.pbtxt
#      - ./paddlex/official_models:/root/.paddlex/official_models
    ports:
      - "8000:8000"            # expose port 8080 from container to host
      - "8001:8001"
    shm_size: 8g               # equivalent to --shm-size 8g
    init: true                 # equivalent to --init
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - xyne

networks:
  xyne:
    external: true
