[    INFO] [2025-10-08 13:16:08,670] [*] [*] - Triton model config: {'name': 'layout-parsing', 'platform': '', 'backend': 'python', 'version_policy': {'latest': {'num_versions': 1}}, 'max_batch_size': 8, 'input': [{'name': 'input', 'data_type': 'TYPE_STRING', 'format': 'FORMAT_NONE', 'dims': [1], 'is_shape_tensor': False, 'allow_ragged_batch': False}], 'output': [{'name': 'output', 'data_type': 'TYPE_STRING', 'dims': [1], 'label_filename': '', 'is_shape_tensor': False}], 'batch_input': [], 'batch_output': [], 'optimization': {'priority': 'PRIORITY_DEFAULT', 'input_pinned_memory': {'enable': True}, 'output_pinned_memory': {'enable': True}, 'gather_kernel_buffer_threshold': 0, 'eager_batching': False}, 'instance_group': [{'name': 'layout-parsing_0', 'kind': 'KIND_GPU', 'count': 2, 'gpus': [0], 'secondary_devices': [], 'profile': [], 'passive': False, 'host_policy': ''}], 'default_model_filename': '', 'cc_model_filenames': {}, 'metric_tags': {}, 'parameters': {}, 'model_warmup': []}
paddlex-server  | [    INFO] [2025-10-08 13:16:08,670] [*] [*] - Input names: ['input']
paddlex-server  | [    INFO] [2025-10-08 13:16:08,670] [*] [*] - Output names: ['output']
paddlex-server  | Creating model: ('PP-DocLayout_plus-L', None)
paddlex-server  | Using official model (PP-DocLayout_plus-L), the model files will be automatically downloaded and saved in /root/.paddlex/official_models.
Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 2290.30it/s]
paddlex-server  | TensorRT dynamic shapes will be loaded from the file.
paddlex-server  | Inference backend: tensorrt
paddlex-server  | Inference backend config: precision='fp16' use_dynamic_shapes=True dynamic_shapes={'im_shape': [[1, 2], [1, 2], [8, 2]], 'image': [[1, 3, 800, 800], [1, 3, 800, 800], [8, 3, 800, 800]], 'scale_factor': [[1, 2], [1, 2], [8, 2]]}
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(719)::CreateTrtEngineFromOnnx     Detect serialized TensorRT Engine file in /root/.paddlex/official_models/PP-DocLayout_plus-L/.cache/tensorrt/trt_serialized.trt, will load it directly.
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: im_shape, shape: [8, 2], The shape range before: min_shape=[-1, 2], max_shape=[-1, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[8, 2], max_shape=[8, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: im_shape, shape: [1, 2], The shape range before: min_shape=[8, 2], max_shape=[8, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 2], max_shape=[8, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: image, shape: [8, 3, 800, 800], The shape range before: min_shape=[-1, 3, 800, 800], max_shape=[-1, 3, 800, 800].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[8, 3, 800, 800], max_shape=[8, 3, 800, 800].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: image, shape: [1, 3, 800, 800], The shape range before: min_shape=[8, 3, 800, 800], max_shape=[8, 3, 800, 800].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 3, 800, 800], max_shape=[8, 3, 800, 800].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: scale_factor, shape: [8, 2], The shape range before: min_shape=[-1, 2], max_shape=[-1, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[8, 2], max_shape=[8, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: scale_factor, shape: [1, 2], The shape range before: min_shape=[8, 2], max_shape=[8, 2].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 2], max_shape=[8, 2].
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(108)::LoadTrtCache        Build TensorRT Engine from cache file: /root/.paddlex/official_models/PP-DocLayout_plus-L/.cache/tensorrt/trt_serialized.trt with shape range information as below,
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(111)::LoadTrtCache        Input name: im_shape, shape=[-1, 2], min=[1, 2], max=[8, 2]
paddlex-server  | 
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(111)::LoadTrtCache        Input name: image, shape=[-1, 3, 800, 800], min=[1, 3, 800, 800], max=[8, 3, 800, 800]
paddlex-server  | 
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(111)::LoadTrtCache        Input name: scale_factor, shape=[-1, 2], min=[1, 2], max=[8, 2]
paddlex-server  | 
paddlex-server  | [ERROR] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(239)::log        3: [runtime.cpp::~Runtime::346] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::346, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
paddlex-server  | )
paddlex-server  | [INFO] ultra_infer/runtime/runtime.cc(320)::CreateTrtBackend  Runtime initialized with Backend::TRT in Device::GPU.
paddlex-server  | Creating model: ('PP-LCNet_x0_25_textline_ori', None)
paddlex-server  | Using official model (PP-LCNet_x0_25_textline_ori), the model files will be automatically downloaded and saved in /root/.paddlex/official_models.
Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 594.01it/s]
paddlex-server  | TensorRT dynamic shapes will be loaded from the file.
paddlex-server  | Inference backend: tensorrt
paddlex-server  | Inference backend config: precision='fp16' use_dynamic_shapes=True dynamic_shapes={'x': [[1, 3, 80, 160], [1, 3, 80, 160], [8, 3, 80, 160]]}
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(719)::CreateTrtEngineFromOnnx     Detect serialized TensorRT Engine file in /root/.paddlex/official_models/PP-LCNet_x0_25_textline_ori/.cache/tensorrt/trt_serialized.trt, will load it directly.
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: x, shape: [8, 3, 80, 160], The shape range before: min_shape=[-1, 3, 80, 160], max_shape=[-1, 3, 80, 160].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[8, 3, 80, 160], max_shape=[8, 3, 80, 160].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: x, shape: [1, 3, 80, 160], The shape range before: min_shape=[8, 3, 80, 160], max_shape=[8, 3, 80, 160].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 3, 80, 160], max_shape=[8, 3, 80, 160].
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(108)::LoadTrtCache        Build TensorRT Engine from cache file: /root/.paddlex/official_models/PP-LCNet_x0_25_textline_ori/.cache/tensorrt/trt_serialized.trt with shape range information as below,
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(111)::LoadTrtCache        Input name: x, shape=[-1, 3, 80, 160], min=[1, 3, 80, 160], max=[8, 3, 80, 160]
paddlex-server  | 
paddlex-server  | [ERROR] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(239)::log        3: [runtime.cpp::~Runtime::346] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::346, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
paddlex-server  | )
paddlex-server  | [INFO] ultra_infer/runtime/runtime.cc(320)::CreateTrtBackend  Runtime initialized with Backend::TRT in Device::GPU.
paddlex-server  | Creating model: ('PP-OCRv5_server_det', None)
paddlex-server  | Using official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in /root/.paddlex/official_models.
Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1168.87it/s]
paddlex-server  | TensorRT dynamic shapes will be loaded from the file.
paddlex-server  | Inference backend: tensorrt
paddlex-server  | Inference backend config: precision='fp16' use_dynamic_shapes=True dynamic_shapes={'x': [[1, 3, 32, 32], [1, 3, 736, 736], [1, 3, 4000, 4000]]}
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(719)::CreateTrtEngineFromOnnx     Detect serialized TensorRT Engine file in /root/.paddlex/official_models/PP-OCRv5_server_det/.cache/tensorrt/trt_serialized.trt, will load it directly.
paddlex-server  | [ERROR] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(239)::log        1: [defaultAllocator.cpp::allocate::19] Error Code 1: Cuda Runtime (out of memory)
paddlex-server  | [ERROR] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(239)::log        2: [executionContext.cpp::ExecutionContext::470] Error Code 2: OutOfMemory (no further information)
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: x, shape: [1, 3, 4000, 4000], The shape range before: min_shape=[-1, 3, -1, -1], max_shape=[-1, 3, -1, -1].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 3, 4000, 4000], max_shape=[1, 3, 4000, 4000].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: x, shape: [1, 3, 32, 32], The shape range before: min_shape=[1, 3, 4000, 4000], max_shape=[1, 3, 4000, 4000].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 3, 32, 32], max_shape=[1, 3, 4000, 4000].
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(108)::LoadTrtCache        Build TensorRT Engine from cache file: /root/.paddlex/official_models/PP-OCRv5_server_det/.cache/tensorrt/trt_serialized.trt with shape range information as below,
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(111)::LoadTrtCache        Input name: x, shape=[-1, 3, -1, -1], min=[1, 3, 32, 32], max=[1, 3, 4000, 4000]
paddlex-server  | 
paddlex-server  | [ERROR] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(239)::log        3: [runtime.cpp::~Runtime::346] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::346, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
paddlex-server  | )
paddlex-server  | [INFO] ultra_infer/runtime/runtime.cc(320)::CreateTrtBackend  Runtime initialized with Backend::TRT in Device::GPU.
paddlex-server  | Creating model: ('PP-OCRv5_server_rec', None)
paddlex-server  | Using official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in /root/.paddlex/official_models.
Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1394.38it/s]
paddlex-server  | TensorRT dynamic shapes will be loaded from the file.
paddlex-server  | Inference backend: tensorrt
paddlex-server  | Inference backend config: precision='fp16' use_dynamic_shapes=True dynamic_shapes={'x': [[1, 3, 48, 160], [1, 3, 48, 320], [8, 3, 48, 3200]]}
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(719)::CreateTrtEngineFromOnnx     Detect serialized TensorRT Engine file in /root/.paddlex/official_models/PP-OCRv5_server_rec/.cache/tensorrt/trt_serialized.trt, will load it directly.
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: x, shape: [8, 3, 48, 3200], The shape range before: min_shape=[-1, 3, 48, -1], max_shape=[-1, 3, 48, -1].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[8, 3, 48, 3200], max_shape=[8, 3, 48, 3200].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(40)::Update  [New Shape Out of Range] input name: x, shape: [1, 3, 48, 160], The shape range before: min_shape=[8, 3, 48, 3200], max_shape=[8, 3, 48, 3200].
paddlex-server  | [WARNING] ultra_infer/runtime/backends/tensorrt/utils.cc(52)::Update  [New Shape Out of Range] The updated shape range now: min_shape=[1, 3, 48, 160], max_shape=[8, 3, 48, 3200].
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(108)::LoadTrtCache        Build TensorRT Engine from cache file: /root/.paddlex/official_models/PP-OCRv5_server_rec/.cache/tensorrt/trt_serialized.trt with shape range information as below,
paddlex-server  | [INFO] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(111)::LoadTrtCache        Input name: x, shape=[-1, 3, 48, -1], min=[1, 3, 48, 160], max=[8, 3, 48, 3200]
paddlex-server  | 
paddlex-server  | [ERROR] ultra_infer/runtime/backends/tensorrt/trt_backend.cc(239)::log        3: [runtime.cpp::~Runtime::346] Error Code 3: API Usage Error (Parameter check failed at: runtime/rt/runtime.cpp::~Runtime::346, condition: mEngineCounter.use_count() == 1. Destroying a runtime before destroying deserialized engines created by the runtime leads to undefined behavior.
paddlex-server  | )
paddlex-server  | [INFO] ultra_infer/runtime/runtime.cc(320)::CreateTrtBackend  Runtime initialized with Backend::TRT in Device::GPU.
paddlex-server  | [    INFO] [2025-10-08 13:16:17,342] [*] [*] - 51b69ce9a1a3428689b03e443e80e6cb initialized successfully
paddlex-server  | W1008 13:18:03.784541    49 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.9, Runtime API Version: 11.8
paddlex-server  | W1008 13:18:03.785306    49 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.
paddlex-server  | [    INFO] [2025-10-08 13:18:03,786] [dfad5cc8868744e3ac2222321576c43a] [08130518-c339-4395-b9c3-93d11b47614e] - Time taken: 824.680 ms


w Enable Watch